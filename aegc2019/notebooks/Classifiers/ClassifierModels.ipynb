{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different Classifier Models: Practicality, Performance and Use Cases\n",
    " \n",
    "**Data** [Sources](../Data/Sources.ipynb) | [Compositional Data](../Data/CompositionalData.ipynb) | [Lambdas](../Data/Lambdas.ipynb) **Classifiers** [Models](../Classifiers/ClassifierModels.ipynb)| [Dimensionality](../Classifiers/Dimensionality.ipynb) | [Performance](../Classifiers/Performance.ipynb) **Visualisation**  [Entropy](../Vis/Entropy.ipynb) | [Manifolds](../Vis/Manifolds.ipynb) **Workflows** [Building Workflows](../BuildingWorkflows.ipynb) **GitHub** [AEGC2019](https://github.com/morganjwilliams/aegc2019) | [pyrolite](https://github.com/morganjwilliams/pyrolite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This notebook introduces some of the classifier models which have been used previously for geochemical tectonic discrimination, and provides minimal working examples for building a working model. For the purpose of developing classification models for tectonic discrimination using bulk-rock geochemical data, Petrelli et al. (2016) use Support Vector Classifiers ([Petrelli2016]), and Ueki et al. (2018) use Support Vector Classifiers, Random Forests and Sparse Multinomial Regression ([Ueki2018]). \n",
    "\n",
    "[Petrelli2016]: https://doi.org/10.1007/s00410-016-1292-2 \"Petrelli, M., Perugini, D., 2016. Solving petrological problems through machine learning: the study case of tectonic discrimination using geochemical and isotopic data. Contrib Mineral Petrol 171, 81.\"\n",
    "[Ueki2018]: https://doi.org/10.1029/2017GC007401 \"Ueki, K., Hino, H., Kuwatani, T., 2018. Geochemical Discrimination and Characteristics of Magmatic Tectonic Settings: A Machine-Learning-Based Approach. Geochemistry, Geophysics, Geosystems 19, 1327â€“1347.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Support Vector Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timeit\n",
    "import warnings\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                        module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multinomial Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups_vectorized('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 20newsgroup, train_samples=16961, n_features=130107, n_classes=20\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.1)\n",
    "train_samples, n_features = X_train.shape\n",
    "n_classes = np.unique(y).shape[0]\n",
    "\n",
    "models = {'ovr': {'name': 'One versus Rest', 'iters': [1, 2, 4]},\n",
    "          'multinomial': {'name': 'Multinomial', 'iters': [1, 3, 7]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model=One versus Rest] Number of epochs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3_64\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model=One versus Rest] Number of epochs: 2\n",
      "[model=One versus Rest] Number of epochs: 4\n",
      "Test accuracy for model ovr: 0.7963\n",
      "% non-zero coefficients for model ovr, per class:\n",
      " [0.72325086 0.51803516 0.47115067 0.74092862 0.61949011 0.63563067\n",
      " 0.4165802  0.6256389  0.44117534 0.55877086 0.70173011 0.51188637\n",
      " 0.71325909 0.55569647 0.38583627 0.67559778 0.48037385 0.41273721\n",
      " 0.4995888  0.86928451]\n",
      "Run time (4 epochs) for model ovr:7.59\n",
      "[model=Multinomial] Number of epochs: 1\n",
      "[model=Multinomial] Number of epochs: 3\n",
      "[model=Multinomial] Number of epochs: 7\n",
      "Test accuracy for model multinomial: 0.7915\n",
      "% non-zero coefficients for model multinomial, per class:\n",
      " [0.45501011 0.26132337 0.15448823 0.29898468 0.32896001 0.22981085\n",
      " 0.13143028 0.34586917 0.30743926 0.35816674 0.23134804 0.21751328\n",
      " 0.38276188 0.31205085 0.27054655 0.38814207 0.59873796 0.19983552\n",
      " 0.18984374 0.36277833]\n",
      "Run time (7 epochs) for model multinomial:6.76\n"
     ]
    }
   ],
   "source": [
    "t0 = timeit.default_timer()\n",
    "for model in models:\n",
    "    # Add initial chance-level values for plotting purpose\n",
    "    accuracies = [1 / n_classes]\n",
    "    times = [0]\n",
    "    densities = [1]\n",
    "\n",
    "    model_params = models[model]\n",
    "\n",
    "    # Small number of epochs for fast runtime\n",
    "    for this_max_iter in model_params['iters']:\n",
    "        print('[model=%s] Number of epochs: %s' %\n",
    "              (model_params['name'], this_max_iter))\n",
    "        lr = LogisticRegression(solver='saga', \n",
    "                                multi_class=model,\n",
    "                                C=1,\n",
    "                                penalty='l1',\n",
    "                                fit_intercept=True,\n",
    "                                max_iter=this_max_iter,\n",
    "                                random_state=42,\n",
    "                                )\n",
    "        t1 = timeit.default_timer()\n",
    "        lr.fit(X_train, y_train)\n",
    "        train_time = timeit.default_timer() - t1\n",
    "\n",
    "        y_pred = lr.predict(X_test)\n",
    "        accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n",
    "        density = np.mean(lr.coef_ != 0, axis=1) * 100\n",
    "        accuracies.append(accuracy)\n",
    "        densities.append(density)\n",
    "        times.append(train_time)\n",
    "    models[model]['times'] = times\n",
    "    models[model]['densities'] = densities\n",
    "    models[model]['accuracies'] = accuracies\n",
    "    print('Test accuracy for model %s: %.4f' % (model, accuracies[-1]))\n",
    "    print('%% non-zero coefficients for model %s, '\n",
    "          'per class:\\n %s' % (model, densities[-1]))\n",
    "    print('Run time (%i epochs) for model %s:'\n",
    "          '%.2f' % (model_params['iters'][-1], model, times[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probablistic Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "livereveal": {
   "autolaunch": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
